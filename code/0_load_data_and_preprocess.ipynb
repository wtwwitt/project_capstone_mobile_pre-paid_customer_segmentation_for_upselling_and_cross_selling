{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and merge for memory saving\n",
    "df = dd.concat([\n",
    "    dd.read_csv('../data/TOL_202309.txt', delimiter='|'),\n",
    "    dd.read_csv('../data/TOL_202310.txt', delimiter='|'),\n",
    "    dd.read_csv('../data/TOL_202311.txt', delimiter='|')\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datetime\n",
    "df['BUY_DATE'] = dd.to_datetime(df['BUY_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date as index\n",
    "# df = df.set_index('BUY_DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PACKAGE_CODE      string[pyarrow]\n",
       "PREFIX            string[pyarrow]\n",
       "CHARGING_TYPE     string[pyarrow]\n",
       "CHANNEL           string[pyarrow]\n",
       "BUY_DATE           datetime64[ns]\n",
       "FUNCTION_VAS      string[pyarrow]\n",
       "GROUP_CHANNEL     string[pyarrow]\n",
       "BUY_TM_KEY_MTH              int64\n",
       "MSISDN                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns, redundant\n",
    "df = df.drop(columns=['BUY_TM_KEY_MTH', 'PREFIX', 'CHARGING_TYPE', 'GROUP_CHANNEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create premium number flag\n",
    "df['Premium_Number'] = df['FUNCTION_VAS'].map(lambda x: 1 if x == 'PREM_ADD_PACKAGE' or x == 'PREM_CANCEL' else 0, meta=('x', 'string[pyarrow]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map function (transaction type) into group\n",
    "df['FUNCTION_VAS'] = df['FUNCTION_VAS'].map({\n",
    "    # Actual function name removed (confidential data) \n",
    "    'FUNCTION 1': 'RC',\n",
    "    'FUNCTION 2': 'BUY',\n",
    "    'FUNCTION 3': 'CANCEL',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incorrect and excluded channels\n",
    "df = df[~df['CHANNEL'].isin(['CHANNEL 1', 'CHANNEL 2', 'CHANNEL 3', 'CHANNEL 4'])] # Actual channel name removed (confidential data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop GROUP_CHANNEL and Map channels into groups\n",
    "mapping = {\n",
    "    # Actual channel name removed (confidential data)\n",
    "    'CHANNEL 1': 'System',\n",
    "    'CHANNEL 2': 'Digital',\n",
    "    'CHANNEL 3': 'Kiosk/POS',\n",
    "    'CHANNEL 4': 'Digital',\n",
    "    'CHANNEL 5': 'Legacy',\n",
    "    'CHANNEL 6': 'Other'\n",
    "}\n",
    "\n",
    "df['CHANNEL'] = df['CHANNEL'].map(lambda x: mapping[x], meta=('x', 'string[pyarrow]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unfocused channel group\n",
    "df = df[~df['CHANNEL'].isin(['Customer Support', 'Campaign', 'Borrow'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only BUY transaction\n",
    "df = df[(df['FUNCTION_VAS'] == 'BUY') | (df['FUNCTION_VAS'] == 'RC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PACKAGE_CODE', 'CHANNEL', 'BUY_DATE', 'FUNCTION_VAS', 'MSISDN',\n",
       "       'Premium_Number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CHANNEL'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare aggregation dict\n",
    "# agg_dict = {col: 'first' for col in ['FUNCTION_VAS', 'Premium_Number']}\n",
    "# agg_dict.update({col: 'sum' for col in ['SYS_TRX', 'DIGITAL_TRX', 'KIOSK_POS_TRX', 'LEGACY_TRX', 'AGENT_TRX']})\n",
    "\n",
    "# temp_df = df[df['BUY_DATE'].dt.month == 9]\n",
    "\n",
    "# # Set index\n",
    "# temp_df['BUY_DATE'] = pd.to_datetime(temp_df['BUY_DATE'])\n",
    "# temp_df.set_index('BUY_DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummified Trx count from each channel as columns\n",
    "# temp_df['SYS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'System' else 0)\n",
    "# temp_df['DIGITAL_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Digital' else 0)\n",
    "# temp_df['KIOSK_POS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Kiosk/POS' else 0)\n",
    "# temp_df['LEGACY_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Legacy' else 0)\n",
    "# temp_df['AGENT_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Agent' else 0)\n",
    "\n",
    "# temp_df.drop(columns='CHANNEL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of transactions for each package/MSISDN\n",
    "# temp_df = temp_df.groupby(['PACKAGE_CODE', 'MSISDN']).resample('W').agg(agg_dict).reset_index().drop(columns='BUY_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to file\n",
    "# temp_df.to_parquet(f'../data/2013_09_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [9, 10, 11]\n",
    "\n",
    "# Prepare aggregation dict\n",
    "agg_dict = {col: 'first' for col in ['FUNCTION_VAS', 'Premium_Number']}\n",
    "agg_dict.update({col: 'sum' for col in ['SYS_TRX', 'DIGITAL_TRX', 'KIOSK_POS_TRX', 'LEGACY_TRX', 'AGENT_TRX']})\n",
    "\n",
    "# Push into pandas dataframe for calculation\n",
    "for month in months:\n",
    "    temp_df = df[df['BUY_DATE'].dt.month == month].compute()\n",
    "\n",
    "    # Set index\n",
    "    temp_df['BUY_DATE'] = pd.to_datetime(temp_df['BUY_DATE'])\n",
    "    temp_df.set_index('BUY_DATE', inplace=True)\n",
    "\n",
    "    # Dummified Trx count from each channel as columns\n",
    "    temp_df['SYS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'System' else 0)\n",
    "    temp_df['DIGITAL_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Digital' else 0)\n",
    "    temp_df['KIOSK_POS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Kiosk/POS' else 0)\n",
    "    temp_df['LEGACY_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Legacy' else 0)\n",
    "    temp_df['AGENT_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Agent' else 0)\n",
    "\n",
    "    temp_df.drop(columns='CHANNEL', inplace=True)\n",
    "\n",
    "    # Count number of transactions for each package/MSISDN\n",
    "    # temp_df = temp_df.groupby(['PACKAGE_CODE', 'MSISDN']).resample('W').agg(agg_dict).reset_index().drop(columns='BUY_DATE')\n",
    "    temp_df = temp_df.groupby(['PACKAGE_CODE', 'MSISDN']).agg(agg_dict).reset_index()\n",
    "\n",
    "\n",
    "    # push to file\n",
    "    temp_df.to_parquet(f'../data/2023_{month}_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# months = [9, 10, 11]\n",
    "# day_range = [(1, 5), (6, 10), (11, 15), (16, 20), (21, 25), (26, 31)]\n",
    "\n",
    "# # Prepare aggregation dict\n",
    "# agg_dict = {col: 'first' for col in ['FUNCTION_VAS', 'Premium_Number']}\n",
    "# agg_dict.update({col: 'sum' for col in ['SYS_TRX', 'DIGITAL_TRX', 'KIOSK_POS_TRX', 'LEGACY_TRX', 'AGENT_TRX']})\n",
    "\n",
    "# # Push into pandas dataframe for calculation\n",
    "# for month in months:\n",
    "#     for day in day_range:\n",
    "#         temp_df = df[(df['BUY_DATE'].dt.month == month) & (df['BUY_DATE'].dt.day >= day[0]) & (df['BUY_DATE'].dt.day <= day[1])].compute()\n",
    "\n",
    "#         # Set index\n",
    "#         temp_df['BUY_DATE'] = pd.to_datetime(temp_df['BUY_DATE'])\n",
    "#         temp_df.set_index('BUY_DATE', inplace=True)\n",
    "\n",
    "#         # Dummified Trx count from each channel as columns\n",
    "#         temp_df['SYS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'System' else 0)\n",
    "#         temp_df['DIGITAL_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Digital' else 0)\n",
    "#         temp_df['KIOSK_POS_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Kiosk/POS' else 0)\n",
    "#         temp_df['LEGACY_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Legacy' else 0)\n",
    "#         temp_df['AGENT_TRX'] = temp_df['CHANNEL'].map(lambda x: 1 if x == 'Agent' else 0)\n",
    "\n",
    "#         temp_df.drop(columns='CHANNEL', inplace=True)\n",
    "\n",
    "#         # Count number of transactions for each package/MSISDN\n",
    "#         temp_df = temp_df.groupby(['PACKAGE_CODE', 'MSISDN']).resample('W').agg(agg_dict).reset_index().drop(columns='BUY_DATE')\n",
    "\n",
    "#         # push to file\n",
    "#         temp_df.to_parquet(f'../data/2023_{month}_{day[0]}_{day[1]}_weekly_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_detail_df = pd.read_csv('../data/PACKAGE_DETAIL_FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename key for merging\n",
    "pack_detail_df = pack_detail_df.rename(columns={'IPK_CODE': 'PACKAGE_CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19802699"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data\n",
    "index = [(0, 6600900), (6600901, 13201800), (13201801, 19802699)]\n",
    "\n",
    "count = 1\n",
    "for idx in index:\n",
    "    temp = df.iloc[idx[0]:idx[1]]\n",
    "    temp = temp.merge(pack_detail_df, on='PACKAGE_CODE', how='left')\n",
    "\n",
    "    # Drop null\n",
    "    temp.dropna(inplace=True)\n",
    "\n",
    "    temp.to_parquet(f'../data/MERGED_DATA_{count}_parquet')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "# df.to_parquet('../data/ALL_DATA_parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
